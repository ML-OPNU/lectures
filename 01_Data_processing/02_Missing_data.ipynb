{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Вирішення проблеми пропущених даних\n",
    "\n",
    "У реальних додатках нерідко трапляються випадки, коли у зразках з різних причин пропущено одне або кілька значень. Можливо, у процес збирання даних вкралася помилка, деякі дані вимірювань виявилися неприйнятними, окремо взяті поля могли просто залишитися незаповненими, наприклад під час опитування. Ми зазвичай розглядаємо пропущені значення як пропуски в таблиці даних або як рядкові заповнювачі, такі як `NaN` (тобто not а number, не число).\n",
    "\n",
    "На жаль, більшість обчислювальних інструментів нездатна обробляти такі пропущені значення або генерує непередбачувані результати, якщо їх просто проігнорувати. Тому, перш ніж продовжити подальший аналіз, вкрай важливо розібратися в цих пропущених значеннях."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Чому дані відсутні у наборі даних?\n",
    "\n",
    "Існує багато причин, чому певні значення відсутні в даних. Причини відсутності даних у наборі даних впливають на підхід до обробки відсутніх даних. Тому необхідно розуміти, чому дані можуть бути відсутніми. Деякі з причин наведені нижче:\n",
    "\n",
    "- минулі дані можуть бути пошкоджені через неналежне обслуговування;\n",
    "- спостереження не реєструються для певних полів з певних причин. Можливий збій у записі значень через людський фактор;\n",
    "- користувач не надав значення навмисно;\n",
    "- відсутність відповіді на питання: Це означає, що учасник відмовився відповідати."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Типи відсутніх значень\n",
    "\n",
    "Виділяють три типи відсутніх даних: \n",
    "\n",
    "- Missing Completely At Random (MCAR);\n",
    "- Missing At Random (MAR);\n",
    "- Missing Not At Random (MNAR).\n",
    "\n",
    "**Missing Completely At Random**. У цьому випадку ймовірність відсутності даних однакова для всіх спостережень. У цьому випадку немає ніякого зв'язку між відсутніми даними та будь-якими іншими значеннями, що спостерігаються або не спостерігаються (дані, які не записані) в даному наборі даних. Тобто, відсутні значення повністю незалежні від інших даних. Немає жодної закономірності.\n",
    "\n",
    "У випадку даних MCAR значення може бути відсутнім через людську помилку, збій системи/обладнання, втрату зразка або незадовільні технічні умови під час запису значень. Наприклад, припустимо, що в бібліотеці є прострочені книги. Деякі значення прострочених книг у комп'ютерній системі відсутні. Причиною може бути людська помилка, наприклад, бібліотекар забув ввести значення. Отже, відсутні значення прострочених книг не пов'язані з будь-якою іншою змінною/даними в системі. Це не повинно бути припущенням, оскільки це рідкісний випадок. Перевага таких даних полягає в тому, що статистичний аналіз залишається неупередженим.\n",
    "\n",
    "**Missing At Random**. Дані MAR означають, що причину відсутності значень можна пояснити змінними, про які ви маєте повну інформацію, оскільки існує певний зв'язок між відсутніми даними та іншими значеннями/даними. У цьому випадку дані відсутні не для всіх спостережень. Вони відсутні лише в межах підвибірок даних, і існує певна закономірність у відсутніх значеннях.\n",
    "\n",
    "Наприклад, якщо ви перевірите дані опитування, ви можете виявити, що всі люди відповіли на питання \"Стать\", але значення \"Вік\" здебільшого відсутні для людей, які відповіли на питання \"Стать\" як \"жіноча\". (Причина в тому, що більшість жінок не хочуть розкривати свій вік).\n",
    "\n",
    "Отже, ймовірність відсутності даних залежить лише від спостережуваного значення або даних. У цьому випадку змінні \"Стать\" і \"Вік\" пов'язані між собою. Причину відсутності значень змінної \"Вік\" можна пояснити змінною \"Стать\", але не можна передбачити саме відсутнє значення.\n",
    "\n",
    "Припустимо, що в бібліотеці проводиться опитування щодо прострочених книг. В опитуванні запитується стать та кількість прострочених книг. Припустимо, що більшість жінок відповідають на опитування, а чоловіки відповідають рідше. Отже, відсутність даних можна пояснити іншим фактором, а саме статтю. У цьому випадку статистичний аналіз може призвести до упередженості. Отримати незміщену оцінку параметрів можна лише шляхом моделювання відсутніх даних.\n",
    "\n",
    "**Missing Not At Random**. Пропущені значення залежать від неспостережуваних даних. Якщо у пропущених даних є певна структура/закономірність, а інші спостережувані дані не можуть її пояснити, то це вважається пропуском не випадковим (MNAR).\n",
    "\n",
    "Якщо відсутні дані не підпадають під MCAR або MAR, їх можна класифікувати як MNAR. Це може статися через небажання людей надавати необхідну інформацію. Певна група респондентів може не відповісти на деякі запитання в опитуванні.\n",
    "\n",
    "Наприклад, уявімо, що в опитуванні про бібліотеку запитують назву та кількість прострочених книг. Більшість людей, які не мають прострочених книг, скоріш за все, відповідатимуть на запитання. Люди, які мають більше прострочених книг, мають менше шансів відповісти на опитування. Отже, в цьому випадку пропущене значення кількості прострочених книг залежить від людей, які мають більше прострочених книг.\n",
    "\n",
    "Іншим прикладом є те, що люди з меншим доходом можуть відмовитися надавати певну інформацію в опитуванні або анкеті. У випадку MNAR статистичний аналіз також може призвести до упередженості."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Набір даних для демонстрації проблеми пропущених даних\n",
    "\n",
    "У якості прикладу розглянемо відомий набір даних `Pima Indians Diabetes Database` або просто `Diabetes Dataset`. Набір даних `Diabetes Dataset` передбачає прогнозування початку діабету протягом 5 років за заданими медичними даними. \n",
    "\n",
    "Це бінарна (2-класова) задача класифікації. Кількість спостережень для кожного класу не збалансована. Є 768 спостережень з 8 вхідними змінними та 1 вихідною змінною. Імена змінних наступні:  \n",
    "\n",
    "0. Кількість вагітностей.\n",
    "1. Концентрація глюкози в плазмі через 2 години після перорального тесту на толерантність до глюкози\n",
    "2. Діастолічний артеріальний тиск (мм рт.ст.)\n",
    "3. Товщина шкірної складки трицепса (мм)\n",
    "4. 2-годинний інсулін сироватки крові (мОд/мл).\n",
    "5. Індекс маси тіла (вага в кг/(зріст в м)^2).\n",
    "6. Функція спадковості по цукровому діабету.\n",
    "7. Вік (роки).\n",
    "8. Змінна класу (0 або 1).\n",
    "\n",
    "Базові показники прогнозування найбільш поширеного класу мають точність класифікації приблизно `65%`. Найкращі результати досягають точності класифікації приблизно `77%`.\n",
    "\n",
    "Відомо, що в цьому наборі даних є пропущені значення. Зокрема, відсутні спостереження для деяких стовпчиків, які позначені нульовим значенням. Ми можемо підтвердити це визначенням цих стовпчиків і знаннями з предметної області, що нульове значення є неприпустимим для цих показників, наприклад, нульове значення для індексу маси тіла або артеріального тиску є неприпустимим."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Позначення відсутніх значень\n",
    "\n",
    "Більшість даних мають пропущені значення, і ймовірність пропущених значень зростає зі збільшенням розміру набору даних.\n",
    "\n",
    "Відсутність даних не є рідкістю в реальних наборах даних. Насправді, ймовірність того, що хоча б одна точка даних буде відсутня, зростає зі збільшенням розміру набору даних.\n",
    "\n",
    "Завантажимо датасет за допомогою бібліотеки Pandas та роздрукуємо зведену статистику за кожним атрибутом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                0           1           2           3           4           5  \\\n",
      "count  768.000000  768.000000  768.000000  768.000000  768.000000  768.000000   \n",
      "mean     3.845052  120.894531   69.105469   20.536458   79.799479   31.992578   \n",
      "std      3.369578   31.972618   19.355807   15.952218  115.244002    7.884160   \n",
      "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "25%      1.000000   99.000000   62.000000    0.000000    0.000000   27.300000   \n",
      "50%      3.000000  117.000000   72.000000   23.000000   30.500000   32.000000   \n",
      "75%      6.000000  140.250000   80.000000   32.000000  127.250000   36.600000   \n",
      "max     17.000000  199.000000  122.000000   99.000000  846.000000   67.100000   \n",
      "\n",
      "                6           7           8  \n",
      "count  768.000000  768.000000  768.000000  \n",
      "mean     0.471876   33.240885    0.348958  \n",
      "std      0.331329   11.760232    0.476951  \n",
      "min      0.078000   21.000000    0.000000  \n",
      "25%      0.243750   24.000000    0.000000  \n",
      "50%      0.372500   29.000000    0.000000  \n",
      "75%      0.626250   41.000000    1.000000  \n",
      "max      2.420000   81.000000    1.000000  \n"
     ]
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "\n",
    "# Завантажуємо датасет, header = None означає, що в датасеті нема першого рядку із заголовками, тому\n",
    "# у першому рядку одразу ідуть значення\n",
    "dataset = read_csv('assets/missing.csv', header = None)\n",
    "\n",
    "# Роздрукування зведеної статистики\n",
    "print(dataset.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ми бачимо, що є стовпці, які мають мінімальне значення `0`. У деяких стовпчиках нульове значення не має сенсу і вказує на невірне або відсутнє значення.\n",
    "\n",
    "**Відсутні значення часто вказують на те, що вони знаходяться за межами діапазону; це може бути від'ємне число (наприклад, `-1`) в числовому полі, яке зазвичай має бути тільки додатним, або `0` в числовому полі, яке зазвичай ніколи не може бути `0`.**\n",
    "\n",
    "Зокрема, наступні стовпчики мають невірне нульове мінімальне значення:\n",
    "\n",
    "1. Концентрація глюкози в плазмі крові\n",
    "2. Діастолічний артеріальний тиск\n",
    "3. Товщина шкірної складки трицепса\n",
    "4. 2-годинний інсулін у сироватці крові\n",
    "5. Індекс маси тіла\n",
    "\n",
    "Підтвердимо це, подивившись на вихідні дані, приклад виводить перші 20 рядків даних."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0    1   2   3    4     5      6   7  8\n",
      "0    6  148  72  35    0  33.6  0.627  50  1\n",
      "1    1   85  66  29    0  26.6  0.351  31  0\n",
      "2    8  183  64   0    0  23.3  0.672  32  1\n",
      "3    1   89  66  23   94  28.1  0.167  21  0\n",
      "4    0  137  40  35  168  43.1  2.288  33  1\n",
      "5    5  116  74   0    0  25.6  0.201  30  0\n",
      "6    3   78  50  32   88  31.0  0.248  26  1\n",
      "7   10  115   0   0    0  35.3  0.134  29  0\n",
      "8    2  197  70  45  543  30.5  0.158  53  1\n",
      "9    8  125  96   0    0   0.0  0.232  54  1\n",
      "10   4  110  92   0    0  37.6  0.191  30  0\n",
      "11  10  168  74   0    0  38.0  0.537  34  1\n",
      "12  10  139  80   0    0  27.1  1.441  57  0\n",
      "13   1  189  60  23  846  30.1  0.398  59  1\n",
      "14   5  166  72  19  175  25.8  0.587  51  1\n",
      "15   7  100   0   0    0  30.0  0.484  32  1\n",
      "16   0  118  84  47  230  45.8  0.551  31  1\n",
      "17   7  107  74   0    0  29.6  0.254  31  1\n",
      "18   1  103  30  38   83  43.3  0.183  33  0\n",
      "19   1  115  70  30   96  34.6  0.529  32  1\n"
     ]
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "\n",
    "# Завантажуємо датасет\n",
    "dataset = read_csv('assets/missing.csv', header = None)\n",
    "\n",
    "print(dataset.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ми можемо підрахувати кількість відсутніх значень у кожному з цих стовпчиків. Ми можемо зробити це, позначивши всі значення у підмножині `DataFrame`, що нас цікавить, які мають нульові значення, як `True`. Після цього ми можемо підрахувати кількість значень `True` у кожному стовпчику."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1      5\n",
      "2     35\n",
      "3    227\n",
      "4    374\n",
      "5     11\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "\n",
    "# Завантажуємо датасет\n",
    "dataset = read_csv('assets/missing.csv', header = None)\n",
    "\n",
    "num_missing = (dataset[[1,2,3,4,5]] == 0).sum()\n",
    "print(num_missing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ми бачимо, що стовпчики 1, 2 і 5 мають лише кілька нульових значень, тоді як у стовпчиках 3 і 4 їх набагато більше - майже половина рядків. Це свідчить про те, що для різних стовпців можуть знадобитися різні стратегії \"пропущених значень\", наприклад, щоб забезпечити наявність достатньої кількості записів для навчання прогнозної моделі.\n",
    "\n",
    "У Python, зокрема у Pandas, NumPy та Scikit-Learn, ми позначаємо пропущені значення як `NaN`. Елементи зі значенням `NaN` ігноруються при виконанні таких операцій, як сума, підрахунок тощо.\n",
    "\n",
    "Ми можемо легко позначити значення як `NaN` за допомогою Pandas `DataFrame`, використовуючи функцію `replace()` на підмножині стовпців, які нас цікавлять. Перш ніж замінити відсутні значення на `NaN`, корисно переконатися, що стовпці містять допустимі числові типи даних, запустивши `dataset.dtypes`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      int64\n",
      "1      int64\n",
      "2      int64\n",
      "3      int64\n",
      "4      int64\n",
      "5    float64\n",
      "6    float64\n",
      "7      int64\n",
      "8      int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "\n",
    "# Завантажуємо датасет\n",
    "dataset = read_csv('assets/missing.csv', header = None)\n",
    "\n",
    "print(dataset.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ми бачимо, що всі стовпці мають тип `int` або `float`. Після того, як ми позначили відсутні значення, ми можемо використати функцію `isull()`, щоб позначити всі значення `NaN` у наборі даних як `True` і отримати підрахунок відсутніх значень для кожного стовпчика."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      0\n",
      "1      5\n",
      "2     35\n",
      "3    227\n",
      "4    374\n",
      "5     11\n",
      "6      0\n",
      "7      0\n",
      "8      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "from numpy import nan\n",
    "\n",
    "# Завантажуємо датасет\n",
    "dataset = read_csv('assets/missing.csv', header = None)\n",
    "\n",
    "# Замінюємо нульові значення на NaN\n",
    "dataset[[1,2,3,4,5]] = dataset[[1,2,3,4,5]].replace(0, nan)\n",
    "\n",
    "# Підраховуємо кількість значень NaN у кожному стовпчику\n",
    "print(dataset.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запуск прикладу виводить кількість пропущених значень у кожному стовпчику. Ми бачимо, що стовпчики 1-5 мають таку ж кількість відсутніх значень, як і нульові значення, визначені вище. Це ознака того, що ми правильно позначили знайдені пропущені значення.\n",
    "\n",
    "Роздрукуємо перші 20 рядків даних:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0      1     2     3      4     5      6   7  8\n",
      "0    6  148.0  72.0  35.0    NaN  33.6  0.627  50  1\n",
      "1    1   85.0  66.0  29.0    NaN  26.6  0.351  31  0\n",
      "2    8  183.0  64.0   NaN    NaN  23.3  0.672  32  1\n",
      "3    1   89.0  66.0  23.0   94.0  28.1  0.167  21  0\n",
      "4    0  137.0  40.0  35.0  168.0  43.1  2.288  33  1\n",
      "5    5  116.0  74.0   NaN    NaN  25.6  0.201  30  0\n",
      "6    3   78.0  50.0  32.0   88.0  31.0  0.248  26  1\n",
      "7   10  115.0   NaN   NaN    NaN  35.3  0.134  29  0\n",
      "8    2  197.0  70.0  45.0  543.0  30.5  0.158  53  1\n",
      "9    8  125.0  96.0   NaN    NaN   NaN  0.232  54  1\n",
      "10   4  110.0  92.0   NaN    NaN  37.6  0.191  30  0\n",
      "11  10  168.0  74.0   NaN    NaN  38.0  0.537  34  1\n",
      "12  10  139.0  80.0   NaN    NaN  27.1  1.441  57  0\n",
      "13   1  189.0  60.0  23.0  846.0  30.1  0.398  59  1\n",
      "14   5  166.0  72.0  19.0  175.0  25.8  0.587  51  1\n",
      "15   7  100.0   NaN   NaN    NaN  30.0  0.484  32  1\n",
      "16   0  118.0  84.0  47.0  230.0  45.8  0.551  31  1\n",
      "17   7  107.0  74.0   NaN    NaN  29.6  0.254  31  1\n",
      "18   1  103.0  30.0  38.0   83.0  43.3  0.183  33  0\n",
      "19   1  115.0  70.0  30.0   96.0  34.6  0.529  32  1\n"
     ]
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "from numpy import nan\n",
    "\n",
    "# Завантажуємо датасет\n",
    "dataset = read_csv('assets/missing.csv', header = None)\n",
    "\n",
    "# Замінюємо нульові значення на NaN\n",
    "dataset[[1,2,3,4,5]] = dataset[[1,2,3,4,5]].replace(0, nan)\n",
    "\n",
    "print(dataset.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "З вихідних даних видно, що позначення пропущених значень дало очікуваний ефект."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Відсутність значень спричиняє проблеми\n",
    "\n",
    "Відсутність значень у наборі даних може призвести до помилок у деяких алгоритмах машинного навчання. Для прикладу, спробуємо скористатися алгоритмом лінійного дискримінантного аналізу (Linear Discriminant Analysis, LDA) на наборі даних з пропущеними значеннями."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import nan\n",
    "from pandas import read_csv\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Завантажуємо датасет\n",
    "dataset = read_csv('assets/missing.csv', header = None)\n",
    "\n",
    "# Замінюємо нульові значення на NaN\n",
    "dataset[[1,2,3,4,5]] = dataset[[1,2,3,4,5]].replace(0, nan)\n",
    "\n",
    "# Розділяємо набір даних на вхідні значення та цільову змінну\n",
    "values = dataset.values\n",
    "X = values[:,:8]\n",
    "y = values[:,8]\n",
    "\n",
    "# Виконання закоментованого нижче коду призведе до помилки\n",
    "\n",
    "# Створюємо об'єкт моделі\n",
    "# model = LinearDiscriminantAnalysis()\n",
    "\n",
    "# Визначаємо процедуру оцінювання моделі\n",
    "# cv = KFold(n_splits=3, shuffle=True, random_state=1)\n",
    "\n",
    "# Оцінюємо модель\n",
    "# При виконанні даної операції буде показана помилка:\n",
    "# ValueError: Input X contains NaN.\n",
    "# LinearDiscriminantAnalysis does not accept missing values encoded as NaN natively\n",
    "# result = cross_val_score(model, X, y, cv=cv, scoring='accuracy')\n",
    "\n",
    "# Роздрукуємо показник середньої точності\n",
    "# print(f'Точність: {result.mean():.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Багато популярних моделей прогнозування, таких як машини опорних векторів, glmnet та нейронні мережі, не можуть терпіти жодної кількості пропущених значень.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Видалення рядків з пропущеними значеннями\n",
    "\n",
    "**Найпростіший підхід до роботи з пропущеними значеннями - видалити всі цільові змінні та\\або дані, які містять пропущені значення.**\n",
    "\n",
    "Ми можемо зробити це, створивши новий Pandas DataFrame з видаленими рядками, що містять пропущені значення. Pandas надає функцію `dropna()`, яку можна використовувати для видалення стовпців або рядків з відсутніми даними. Ми можемо використати `dropna()` для видалення всіх рядків з відсутніми даними:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 9)\n",
      "(392, 9)\n"
     ]
    }
   ],
   "source": [
    "from numpy import nan\n",
    "from pandas import read_csv\n",
    "\n",
    "# Завантажуємо датасет\n",
    "dataset = read_csv('assets/missing.csv', header = None)\n",
    "\n",
    "# Роздрукуємо \"форму\" датасету, тобто кількість рядків та сповпців\n",
    "print(dataset.shape)\n",
    "\n",
    "# Замінюємо нульові значення на NaN\n",
    "dataset[[1,2,3,4,5]] = dataset[[1,2,3,4,5]].replace(0, nan)\n",
    "\n",
    "# Видалення пропущених значень. Параметр inplace визначає, що повертає метод\n",
    "# Якщо параметр дорівнює True, видалення відбувається безпосередньо в датасеті, для\n",
    "# якого був викликаний метод. Якщо параметр дорівнює False, метод dropna() повертає новий датасет\n",
    "# з видаленими пропущеними значеннями, об'єкт, для якого був викликаний метод, залишається незмінним.\n",
    "dataset.dropna(inplace=True)\n",
    "\n",
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тепер у нас є набір даних, який ми можемо використовувати для оцінки алгоритму, чутливого до пропущених значень, такого як LDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точність: 0.781\n"
     ]
    }
   ],
   "source": [
    "from numpy import nan\n",
    "from pandas import read_csv\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Завантажуємо датасет\n",
    "dataset = read_csv('assets/missing.csv', header = None)\n",
    "\n",
    "# Замінюємо нульові значення на NaN\n",
    "dataset[[1,2,3,4,5]] = dataset[[1,2,3,4,5]].replace(0, nan)\n",
    "\n",
    "# Видалення пропущених значень\n",
    "dataset.dropna(inplace=True)\n",
    "\n",
    "# Розділяємо набір даних на вхідні значення та цільову змінну\n",
    "values = dataset.values\n",
    "X = values[:,:8]\n",
    "y = values[:,8]\n",
    "\n",
    "# Створюємо об'єкт моделі\n",
    "model = LinearDiscriminantAnalysis()\n",
    "\n",
    "# Визначаємо процедуру оцінювання моделі\n",
    "cv = KFold(n_splits=3, shuffle=True, random_state=1)\n",
    "\n",
    "# Оцінюємо модель\n",
    "result = cross_val_score(model, X, y, cv=cv, scoring='accuracy')\n",
    "\n",
    "# Роздрукуємо показник середньої точності\n",
    "print(f'Точність: {result.mean():.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Недоліком даного подходу є те, що видалення рядків із пропущеними значеннями може суттєво зменшити об'єм вибірки та призвести до зменшення якості навчання моделі. Тому далі треба розглянути інші стратегії для вирішення проблеми пропущених рядків."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Імпутація пропущених значень\n",
    "\n",
    "Імпутація - це використання моделі для заміни відсутніх значень. Існує багато варіантів, які можна розглянути, наприклад, при заміні відсутнього значення:\n",
    "\n",
    "- постійне значення, яке має значення в межах домену, наприклад, 0, відмінне від усіх інших значень;\n",
    "- значення з іншого випадково вибраного запису;\n",
    "- середнє, медіана або мода для стовпчика;\n",
    "- значення, оцінене іншою моделлю прогнозування.\n",
    "\n",
    "Будь-яке обчислення, виконане на навчальному наборі даних, доведеться виконувати на нових даних у майбутньому, коли знадобляться прогнози від доопрацьованої моделі. Це потрібно враховувати при виборі способу обчислення пропущених значень. Наприклад, якщо ви вирішите провести імпутацію за середніми значеннями стовпців, ці середні значення стовпців потрібно буде зберегти у файлі для подальшого використання з новими даними, які містять пропущені значення.\n",
    "\n",
    "Pandas надає функцію `fillna()` для заміни пропущених значень певним значенням. Використаємо цю функцію для заміни відсутпніх значень середніми значеннями для кожного стовпчику:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    0\n",
      "5    0\n",
      "6    0\n",
      "7    0\n",
      "8    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "from numpy import nan\n",
    "\n",
    "dataset = read_csv('assets/missing.csv', header = None)\n",
    "\n",
    "# Замінюємо нульові значення на NaN\n",
    "dataset[[1,2,3,4,5]] = dataset[[1,2,3,4,5]].replace(0, nan)\n",
    "\n",
    "# Заповнюємо пропущені значення середніми значеннями стовпців\n",
    "dataset.fillna(dataset.mean(), inplace=True)\n",
    "\n",
    "# Підрахуємо кількість значень NaN у кожному стовпчику\n",
    "print(dataset.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Бібліотека scikit-learn надає клас попередньої обробки [`SimpleImputer`](https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html), який можна використовувати для заміни відсутніх значень.\n",
    "\n",
    "Це гнучкий клас, який дозволяє вам вказати значення для заміни (це може бути щось інше, ніж `NaN`) і метод, який використовується для заміни (наприклад, середнє значення, медіана або мода). Клас `SimpleImputer` працює безпосередньо з масивом NumPy замість DataFrame.\n",
    "\n",
    "У наведеному нижче прикладі клас `SimpleImputer` замінює відсутні значення середнім значенням кожного стовпчика, а потім виводить кількість значень `NaN` у перетвореній матриці."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Відсутні значення: 0\n"
     ]
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "from numpy import nan\n",
    "from numpy import isnan\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "dataset = read_csv('assets/missing.csv', header = None)\n",
    "\n",
    "# Замінюємо нульові значення на NaN\n",
    "dataset[[1,2,3,4,5]] = dataset[[1,2,3,4,5]].replace(0, nan)\n",
    "\n",
    "# Отримуємо масив numpy\n",
    "values = dataset.values\n",
    "\n",
    "# Створюємо об'єкт імпутера\n",
    "imputer = SimpleImputer(missing_values=nan, strategy='mean')\n",
    "\n",
    "# Трансформуємо датасет\n",
    "transformed_values = imputer.fit_transform(values)\n",
    "\n",
    "# Підрахуємо кількість значень NaN у кожному стовпчику\n",
    "print(f'Відсутні значення: {isnan(transformed_values).sum()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Імпутація пропущених значень за допомогою KNN-імпутера\n",
    "\n",
    "Дотепер ми розглядали прості стратегії імпутації за допомогою методу pandas `fillna()` та `SimpleImputer` від scikit-learn.\n",
    "\n",
    "Імпутація KNN або K найближчих сусідів є ще однією технікою для обробки пропущених значень. Для виконання цієї імпутації ви можете використовувати клас `KNNImputer` з scikit-learn.\n",
    "\n",
    "Для точки даних з відсутніми значеннями цей метод визначає `K` найближчих точок за обраною метрикою відстані (за замовчуванням - евклідова). Кількість найближчих точок або сусідів задається параметром `n_neighbors`. За замовчуванням розглядаються 5 найближчих сусідів.\n",
    "\n",
    "Розглянемо функцію з пропущеними значеннями. Відсутнє значення є середнім значенням значень цієї ознаки для `K` найближчих сусідів, за замовчуванням зважених рівномірно.\n",
    "\n",
    "У наведеному нижче прикладі використовується клас `KNNImputer` з `n_neighbors`, встановленим у `4`, для обчислення відсутніх значень за алгоритмом найближчих сусідів."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вістутні значення: 0\n"
     ]
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "from numpy import nan\n",
    "from numpy import isnan\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "dataset = read_csv('assets/missing.csv', header = None)\n",
    "\n",
    "# Замінюємо нульові значення на NaN\n",
    "dataset[[1,2,3,4,5]] = dataset[[1,2,3,4,5]].replace(0, nan)\n",
    "\n",
    "# Отримуємо масив numpy\n",
    "values = dataset.values\n",
    "\n",
    "# Створюємо об'єкт імпутера\n",
    "imputer = KNNImputer(n_neighbors=4)\n",
    "\n",
    "# Трансформуємо набір даних\n",
    "transformed_values = imputer.fit_transform(values)\n",
    "\n",
    "# Підрахуємо кількість значень NaN у кожному стовпчику\n",
    "print(f'Вістутні значення: {isnan(transformed_values).sum()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Розглянемо приклад роботи алгоритму LDA з трансформованим набором даних. Щоб уникнути витоку даних, ми використовуємо KNN імпутер в конвеєрі разом з LDA класифікатором, щоб він підходив лише до вибірок з навчального набору даних."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точність: 0.763\n"
     ]
    }
   ],
   "source": [
    "from numpy import nan\n",
    "from pandas import read_csv\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "dataset = read_csv('assets/missing.csv', header = None)\n",
    "\n",
    "# Замінюємо нульові значення на NaN\n",
    "dataset[[1,2,3,4,5]] = dataset[[1,2,3,4,5]].replace(0, nan)\n",
    "\n",
    "# Розділяємо набір даних на вхідні значення та цільову змінну\n",
    "values = dataset.values\n",
    "X = values[:,:8]\n",
    "y = values[:,8]\n",
    "\n",
    "# Створюємо об'єкт імпутера\n",
    "imputer = KNNImputer(n_neighbors=4)\n",
    "\n",
    "# Створюємо об'єкт моделі\n",
    "model = LinearDiscriminantAnalysis()\n",
    "\n",
    "# Визначаємо конвеєр для моделювання\n",
    "pipeline = Pipeline(steps=[('imputer', imputer),('model', model)])\n",
    "\n",
    "# Визначаємо процедуру оцінювання моделі\n",
    "cv = KFold(n_splits=3, shuffle=True, random_state=1)\n",
    "\n",
    "# Оцінюємо модель\n",
    "result = cross_val_score(pipeline, X, y, cv=cv, scoring='accuracy')\n",
    "\n",
    "# Роздрукуємо показник середньої точності\n",
    "print(f'Точність: {result.mean():.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Імпутація пропущених значень за допомогою ітеративного імпутатора\n",
    "\n",
    "Клас `IterativeImputer` від Scikit-learn - це більш складна техніка багатовимірної імплікації.\n",
    "\n",
    "`IterativeImputer` прогнозує відсутні значення ознаки, моделюючи її як функцію інших ознак. Таким чином, імпутер прогнозує відсутні значення ознаки, використовуючи інші ознаки як предиктори. Потім він обчислює всі пропущені показники по колу. Ця процедура продовжується ітеративно протягом `max_iter` кількості разів і за замовчуванням дорівнює `10`. Оскільки функція `IterativeImputer` все ще є експериментальною, ви повинні увімкнути її явно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вістутні значення: 0\n"
     ]
    }
   ],
   "source": [
    "from numpy import nan\n",
    "from pandas import read_csv\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "dataset = read_csv('assets/missing.csv', header = None)\n",
    "\n",
    "# Замінюємо нульові значення на NaN\n",
    "dataset[[1,2,3,4,5]] = dataset[[1,2,3,4,5]].replace(0, nan)\n",
    "\n",
    "# Розділяємо набір даних на вхідні значення та цільову змінну\n",
    "values = dataset.values\n",
    "\n",
    "# Створюємо об'єкт імпутера\n",
    "imputer = IterativeImputer(random_state=0)\n",
    "\n",
    "# Трансформуємо набір даних\n",
    "transformed_values = imputer.fit_transform(values)\n",
    "\n",
    "# Підрахуємо кількість значень NaN у кожному стовпчику\n",
    "print(f'Вістутні значення: {isnan(transformed_values).sum()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Розглянемо приклад роботи з алгоритмом LDA з використанням `IterativeImputer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точність: 0.760\n"
     ]
    }
   ],
   "source": [
    "from numpy import nan\n",
    "from pandas import read_csv\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "dataset = read_csv('assets/missing.csv', header = None)\n",
    "\n",
    "# Замінюємо нульові значення на NaN\n",
    "dataset[[1,2,3,4,5]] = dataset[[1,2,3,4,5]].replace(0, nan)\n",
    "\n",
    "# Розділяємо набір даних на вхідні значення та цільову змінну\n",
    "values = dataset.values\n",
    "X = values[:,:8]\n",
    "y = values[:,8]\n",
    "\n",
    "# Створюємо об'єкт імпутера\n",
    "imputer = IterativeImputer(random_state=1)\n",
    "\n",
    "# Створюємо об'єкт моделі\n",
    "model = LinearDiscriminantAnalysis()\n",
    "\n",
    "# Визначаємо конвеєр для моделювання\n",
    "pipeline = Pipeline(steps=[('imputer', imputer),('model', model)])\n",
    "\n",
    "# Визначаємо процедуру оцінювання моделі\n",
    "cv = KFold(n_splits=3, shuffle=True, random_state=1)\n",
    "\n",
    "# Оцінюємо модель\n",
    "result = cross_val_score(pipeline, X, y, cv=cv, scoring='accuracy')\n",
    "\n",
    "# Роздрукуємо показник середньої точності\n",
    "print(f'Точність: {result.mean():.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Алгоритми, які працюють за умов наявності пропущених значень\n",
    "\n",
    "Не всі алгоритми дають збій за відсутності даних.\n",
    "\n",
    "Існують алгоритми, які можна зробити стійкими до пропущених даних, наприклад, метод k-найближчих сусідів, який може ігнорувати стовпчик з виміру відстані, коли значення відсутнє. Наївний Байєс також може підтримувати відсутні значення при прогнозуванні.\n",
    "\n",
    "Існують також алгоритми, які можуть використовувати відсутнє значення як унікальне і відмінне від інших при побудові прогнозної моделі, наприклад, класифікаційні та регресійні дерева.\n",
    "\n",
    "Реалізації scikit-learn для бустінг-оцінок природно обробляють пропущені значення. Однак scikit-learn реалізації наївного байєсу, дерев рішень та k-найближчих сусідів не є стійкими до пропущених значень."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Кодування пропущених значень за допомогою MissingIndicator\n",
    "\n",
    "Модуль Scikit-learn Impute також надає клас `MissingIndicator` для створення бінарних індикаторів пропущених значень у наборах даних. Позначення відсутніх значень за допомогою індикаторів корисно в наступному:\n",
    "\n",
    "- розуміння шаблонів пропусків у даних;\n",
    "- керування стратегіями інтерполяції для різних ознак;\n",
    "- створення нової ознаки, яка вказує на наявність або відсутність значень для певної ознаки.\n",
    "\n",
    "У наступному прикладі показано, як використовувати `MissingIndicator` для позначення відсутніх значень і отримання матриці бінарних індикаторів. Параметр `features` за замовчуванням має значення `missing-only`, щоб включити лише стовпці ознаки з відсутніми значеннями."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вістутні значення: \n",
      "[[False False False  True False]\n",
      " [False False False  True False]\n",
      " [False False  True  True False]\n",
      " ...\n",
      " [False False False False False]\n",
      " [False False  True  True False]\n",
      " [False False False  True False]]\n"
     ]
    }
   ],
   "source": [
    "from numpy import nan\n",
    "from numpy import isnan\n",
    "from pandas import read_csv\n",
    "from sklearn.impute import MissingIndicator\n",
    "\n",
    "dataset = read_csv('assets/missing.csv', header = None)\n",
    "\n",
    "# Замінюємо нульові значення на NaN\n",
    "dataset[[1,2,3,4,5]] = dataset[[1,2,3,4,5]].replace(0, nan)\n",
    "\n",
    "# Розділяємо набір даних на вхідні значення та цільову змінну\n",
    "values = dataset.values\n",
    "\n",
    "# Створюємо об'єкт індикатора\n",
    "indicator = MissingIndicator(features=\"missing-only\", error_on_new=True)\n",
    "\n",
    "# Трансформуємо набір даних\n",
    "transformed_values = indicator.fit_transform(values)\n",
    "\n",
    "# Підрахуємо кількість значень NaN у кожному стовпчику\n",
    "print(f'Вістутні значення: \\n{transformed_values}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Витік даних в процесі імпутації пропущених значень\n",
    "\n",
    "**Витік даних (Data leakage)** при імпутації пропущених значень - це ситуація, коли інформація з тестового набору даних ненароком використовується під час тренування моделі, що може призвести до переоцінки її ефективності. Це особливо актуально, коли використовуються методи імпутації, що залежать від статистичних характеристик всього набору даних.\n",
    "\n",
    "Якщо для імпутації пропущених значень використовуються статистики (середнє, медіана, мода тощо), отримані з усього набору даних, включно з тестовими даними, це може призвести до витоку даних. Наприклад, якщо медіана використовується для заповнення пропусків і вона розрахована на основі всього набору даних, то модель непомітно отримує інформацію про розподіл тестових даних.\n",
    "\n",
    "Один із способів уникнути витоку даних - це розділити дані на тренувальну та тестову вибірки до імпутації. Імпутація тренувальної вибірки повинна виконуватися незалежно, використовуючи лише статистики, отримані з цієї вибірки. Тестові дані потім можуть бути імпутовані використовуючи статистики, отримані тільки з тренувального набору.\n",
    "\n",
    "Якщо використовуються більш складні методи імпутації, наприклад, машинне навчання, то тренування таких моделей повинно виконуватись тільки на тренувальних даних. Модель, використана для імпутації, не повинна бути обучена на тестових даних, навіть непрямо через характеристики набору даних.\n",
    "\n",
    "Під час використання крос-валідації імпутація повинна проводитися окремо в кожному фолді. Це запобігає використанню інформації з валидаційного фолду при обчисленні статистик для імпутації.\n",
    "\n",
    "Завжди важливо моніторити імпутовані значення та перевіряти, чи не призвела імпутація до нелогічних чи неправдоподібних значень. Також корисно перевіряти, чи не впливає імпутація на зміщення моделі.\n",
    "\n",
    "Загалом, ключ до уникнення витоку даних при імпутації полягає у суворому розділенні даних на тренувальні та тестові перед імпутацією та у використанні лише інформації з тренувальної вибірки для обчислення статистик, які використовуються при імпутації."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
